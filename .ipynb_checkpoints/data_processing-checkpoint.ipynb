{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc90a99",
   "metadata": {},
   "source": [
    "# Loading, processing, and resaving 2015-2021 data for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab6b23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "import math\n",
    "\n",
    "import datetime as dt\n",
    "import matplotlib.dates\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e91694d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full</th>\n",
       "      <th>Spaced</th>\n",
       "      <th>Key</th>\n",
       "      <th>Key2</th>\n",
       "      <th>Key3</th>\n",
       "      <th>Key4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alipur, Delhi - DPCC</td>\n",
       "      <td>Alipur</td>\n",
       "      <td>Alipur</td>\n",
       "      <td>Alipur</td>\n",
       "      <td>Alipur</td>\n",
       "      <td>Alipur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anand Vihar, Delhi - DPCC</td>\n",
       "      <td>Anand Vihar</td>\n",
       "      <td>Anand</td>\n",
       "      <td>AnandVihar</td>\n",
       "      <td>AnandVihar</td>\n",
       "      <td>AnandVihar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashok Vihar, Delhi - DPCC</td>\n",
       "      <td>Ashok Vihar</td>\n",
       "      <td>Ashok</td>\n",
       "      <td>AshokVihar</td>\n",
       "      <td>AshokVihar</td>\n",
       "      <td>AshokVihar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aya Nagar, Delhi - IMD</td>\n",
       "      <td>Aya Nagar</td>\n",
       "      <td>Aya</td>\n",
       "      <td>AyaNagar</td>\n",
       "      <td>AyaNagar</td>\n",
       "      <td>AyaNagar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bawana, Delhi - DPCC</td>\n",
       "      <td>Bawana</td>\n",
       "      <td>Bawana</td>\n",
       "      <td>Bawana</td>\n",
       "      <td>Bawana</td>\n",
       "      <td>Bawana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Full       Spaced     Key        Key2        Key3  \\\n",
       "0       Alipur, Delhi - DPCC       Alipur  Alipur      Alipur      Alipur   \n",
       "1  Anand Vihar, Delhi - DPCC  Anand Vihar   Anand  AnandVihar  AnandVihar   \n",
       "2  Ashok Vihar, Delhi - DPCC  Ashok Vihar   Ashok  AshokVihar  AshokVihar   \n",
       "3     Aya Nagar, Delhi - IMD    Aya Nagar     Aya    AyaNagar    AyaNagar   \n",
       "4       Bawana, Delhi - DPCC       Bawana  Bawana      Bawana      Bawana   \n",
       "\n",
       "         Key4  \n",
       "0      Alipur  \n",
       "1  AnandVihar  \n",
       "2  AshokVihar  \n",
       "3    AyaNagar  \n",
       "4      Bawana  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of stations\n",
    "stations_file = '~/Documents/GitHub/HMEI-2021/stations.csv'\n",
    "\n",
    "df_stations = pd.read_csv(stations_file)\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686564a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to stations by preset keys\n",
    "stations20_21 = [s for s in df_stations['Key3'] if type(s) == str]\n",
    "stations15_19 = [s for s in df_stations['Key4'] if type(s) == str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb7ea9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(stations20_21))\n",
    "print(len(stations15_19))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768991e4",
   "metadata": {},
   "source": [
    "# Load and join 2015-19 data with 2020-21 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e223eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that each date corresponds to the correct index\n",
    "# valid if nothing is printed\n",
    "def checkDates(dates, indices, new):\n",
    "    # if new, check only the \"new\" stations, those not in the 2015-19 set\n",
    "    if new:\n",
    "        stations = [x for x in stations20_21 if x not in stations15_19]\n",
    "    else:\n",
    "        stations = stations15_19 # only check stations in the 2015-19 set\n",
    "    for station in stations:\n",
    "        printed = False\n",
    "        if station_data[station].index[indices[0]] != pd.to_datetime(dates[0]):\n",
    "            print(station)\n",
    "            printed = True\n",
    "            print(station_data[station].loc[dates[0]])\n",
    "        for i in range(1, len(dates)):\n",
    "            if station_data[station].index[indices[i]] != pd.to_datetime(dates[i]):\n",
    "                if not printed:\n",
    "                    print(station)\n",
    "                    printed = True\n",
    "                print(station_data[station].loc[dates[i]])\n",
    "        if printed:\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "922c9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pollutants = ['PM2.5', 'PM10', 'NO2', 'SO2', 'Ozone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9594a145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done Alipur\n",
      "done AnandVihar\n",
      "done AshokVihar\n",
      "done AyaNagar\n",
      "done Bawana\n",
      "done CRRI\n",
      "done DTU\n",
      "done Dwarka8\n",
      "done IGI\n",
      "done ITO\n",
      "done Jahangirpuri\n",
      "done JNStadium\n",
      "done Lodhi_IMD\n",
      "done MajorDhyanChand\n",
      "done MandirMarg\n",
      "done Mundka\n",
      "done Najafgarh\n",
      "done Narela\n",
      "done NehruNagar\n",
      "done NorthCampus\n",
      "done NSITDwarka\n",
      "done Okhla\n",
      "done Patparganj\n",
      "done PunjabiBagh\n",
      "done Pusa_DPCC\n",
      "done RKPuram\n",
      "done Rohini\n",
      "done Shadipur\n",
      "done Sirifort\n",
      "done SoniaVihar\n",
      "done SriAuro\n",
      "done VivekVihar\n",
      "done Wazirpur\n"
     ]
    }
   ],
   "source": [
    "station_data = {} # dictionary to store each station's data\n",
    "\n",
    "# load data from Jan, 2015-Nov, 2019\n",
    "for station in stations15_19:\n",
    "    file_str = '~/Documents/GitHub/HMEI-2021/Data 2015-19/data_' + station + '.csv'\n",
    "    df_station = pd.read_csv(file_str, nrows=43345)\n",
    "\n",
    "    # set datetime as index\n",
    "    df_station.index = pd.to_datetime(df_station['From Date'], dayfirst=True)\n",
    "\n",
    "    # reorder columns uniformly\n",
    "    cols = [p for p in pollutants if p in df_station.columns]\n",
    "    df_station = df_station[cols]\n",
    "\n",
    "    end_date = pd.to_datetime('2019-11-30 23:00:00')\n",
    "    df_station = df_station.loc[:end_date]\n",
    "\n",
    "    for col in df_station.columns:\n",
    "        df_station[col] = pd.to_numeric(df_station[col], errors='coerce')\n",
    "\n",
    "    station_data[station] = df_station\n",
    "    \n",
    "    print('done', station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f1391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkDates(['2015-01-01 00:00:00', '2019-11-30 23:00:00'], [0, -1], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "672616ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done Alipur\n",
      "done AnandVihar\n",
      "done AshokVihar\n",
      "done AyaNagar\n",
      "done Bawana\n",
      "done CRRI\n",
      "done DTU\n",
      "done Dwarka8\n",
      "done IGI\n",
      "done ITO\n",
      "done Jahangirpuri\n",
      "done JNStadium\n",
      "done Lodhi_IMD\n",
      "done MajorDhyanChand\n",
      "done MandirMarg\n",
      "done Mundka\n",
      "done Najafgarh\n",
      "done Narela\n",
      "done NehruNagar\n",
      "done NorthCampus\n",
      "done NSITDwarka\n",
      "done Okhla\n",
      "done Patparganj\n",
      "done PunjabiBagh\n",
      "done Pusa_DPCC\n",
      "done RKPuram\n",
      "done Rohini\n",
      "done Shadipur\n",
      "done Sirifort\n",
      "done SoniaVihar\n",
      "done SriAuro\n",
      "done VivekVihar\n",
      "done Wazirpur\n"
     ]
    }
   ],
   "source": [
    "# load data for Dec, 2019\n",
    "for station in stations15_19:\n",
    "    file_str = '~/Documents/GitHub/HMEI-2021/Data 2015-19/Missing Data/data_' + station + '.xlsx'\n",
    "    df_station = pd.read_excel(file_str, skiprows=16)\n",
    "\n",
    "    # set datetime as index\n",
    "    df_station.index = pd.to_datetime(df_station['From Date'], dayfirst=True)\n",
    "\n",
    "    # reorder columns uniformly\n",
    "    cols = [p for p in pollutants if p in df_station.columns]\n",
    "    df_station = df_station[cols]\n",
    "\n",
    "    end_date = pd.to_datetime('2019-12-31 23:00:00')\n",
    "    df_station = df_station.loc[:end_date]\n",
    "\n",
    "    for col in df_station.columns:\n",
    "        df_station[col] = pd.to_numeric(df_station[col], errors='coerce')\n",
    "\n",
    "    station_data[station] = station_data[station].append(df_station) \n",
    "    \n",
    "    print('done', station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cacf763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkDates(['2015-01-01 00:00:00', '2019-12-31 23:00:00'], [0, -1], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb3366df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done Alipur\n",
      "done AnandVihar\n",
      "done AshokVihar\n",
      "done AyaNagar\n",
      "done Bawana\n",
      "done Chandni\n",
      "done CRRI\n",
      "done DTU\n",
      "done Dwarka8\n",
      "done EastArjun\n",
      "done IGI\n",
      "done IHBAS\n",
      "done ITO\n",
      "done Jahangirpuri\n",
      "done JNStadium\n",
      "done Karni\n",
      "done Lodhi_IITM\n",
      "done Lodhi_IMD\n",
      "done MajorDhyanChand\n",
      "done MandirMarg\n",
      "done Mundka\n",
      "done Najafgarh\n",
      "done Narela\n",
      "done NehruNagar\n",
      "done NorthCampus\n",
      "done NSITDwarka\n",
      "done Okhla\n",
      "done Patparganj\n",
      "done PunjabiBagh\n",
      "done Pusa_DPCC\n",
      "done Pusa_IMD\n",
      "done RKPuram\n",
      "done Rohini\n",
      "done Shadipur\n",
      "done Sirifort\n",
      "done SoniaVihar\n",
      "done SriAuro\n",
      "done VivekVihar\n",
      "done Wazirpur\n"
     ]
    }
   ],
   "source": [
    "for station in stations20_21:\n",
    "    file_str = '~/Documents/GitHub/HMEI-2021/Data 2020-21/data_' + station + '.xlsx'\n",
    "    df_station = pd.read_excel(file_str, skiprows=16)\n",
    "\n",
    "    # set datetime as index\n",
    "    df_station.index = pd.to_datetime(df_station['From Date'], dayfirst=True)\n",
    "\n",
    "    cols = [p for p in pollutants if p in df_station.columns]\n",
    "    df_station = df_station[cols]\n",
    "\n",
    "    end_date = pd.to_datetime('2021-05-31 23:45:00')\n",
    "    df_station = df_station.loc[:end_date]\n",
    "\n",
    "    # print(station)\n",
    "    # print(df_station.loc['2021-05-06 00:15:00'])\n",
    "\n",
    "    # convert data to numeric\n",
    "    for col in df_station.columns:\n",
    "        df_station[col] = pd.to_numeric(df_station[col], errors='coerce')\n",
    "\n",
    "    # print(df_station.loc['2021-05-06 00:15:00'])\n",
    "\n",
    "    hourly = df_station.resample('H').mean().loc[:'2021-05-31']\n",
    "\n",
    "    # print(hourly.loc['2021-05-06 01:00:00'])\n",
    "    # print()\n",
    "\n",
    "    if station in stations15_19:\n",
    "        station_data[station] = station_data[station].append(hourly)\n",
    "    else:\n",
    "        station_data[station] = hourly\n",
    "    \n",
    "    print('done', station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3cbebd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkDates(['2015-01-01 00:00:00', '2021-05-31 23:00:00', '2019-12-31 23:00:00', '2020-01-01 00:00:00'], \n",
    "           [0, -1, 43823, 43824], False)\n",
    "checkDates(['2020-01-01 00:00:00', '2021-05-31 23:00:00'], [0, -1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "652bac74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 4)\n",
      "(56232, 5)\n",
      "(56232, 4)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 4)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 4)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 4)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(56232, 5)\n",
      "(12408, 5)\n",
      "(12408, 2)\n",
      "(12408, 5)\n",
      "(12408, 5)\n",
      "(12408, 5)\n",
      "(12408, 4)\n"
     ]
    }
   ],
   "source": [
    "for station in station_data:\n",
    "    print(station_data[station].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79b477",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a36d2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove values which repeat for >= 24 consecutive hours\n",
    "# and values in excess of the monitor's range (> 999.99)\n",
    "def removeBadVals(df, station):\n",
    "    printed = False\n",
    "    ts_index = df.index\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_printed = False\n",
    "        \n",
    "        i = 0\n",
    "        while i + 24 < len(df[col]):\n",
    "            val = df.loc[ts_index[i], col]\n",
    "            \n",
    "            # if value is missing\n",
    "            if math.isnan(val):\n",
    "                i += 1\n",
    "                continue\n",
    "                \n",
    "            # if value is above the reported range\n",
    "            if val > 999.99:\n",
    "                df.loc[ts_index[i], col] = math.nan\n",
    "                if not printed:\n",
    "                    print(station)\n",
    "                    print()\n",
    "                    printed = True\n",
    "                if not col_printed:\n",
    "                    print(col + ':')\n",
    "                    col_printed = True\n",
    "                print(str(ts_index[i]) + '\\t\\t\\t\\tExcess Value: ' + str(val))\n",
    "                print()\n",
    "                i += 1\n",
    "                continue\n",
    "                \n",
    "            at_24 = df.loc[ts_index[i+24], col]\n",
    "            \n",
    "            # if values 24-hours apart do not match\n",
    "            if math.isnan(at_24):\n",
    "                i += 1\n",
    "                continue\n",
    "            if val != at_24:\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # if values 24-hours apart *do* match\n",
    "            j = i\n",
    "            k = i + 24\n",
    "            delete = True\n",
    "            while k >= j:\n",
    "                at_j = df.loc[ts_index[j], col]\n",
    "                at_k = df.loc[ts_index[k], col]\n",
    "                if math.isnan(at_j) or math.isnan(at_k):\n",
    "                    delete = False\n",
    "                    break\n",
    "                # check that all values between indices j and k are the same\n",
    "                elif at_j != at_k:\n",
    "                    delete = False\n",
    "                    break\n",
    "                # and that they are the same as the initial value at index i\n",
    "                elif at_j != val:\n",
    "                    delete = False\n",
    "                    break\n",
    "                j += 1\n",
    "                k -= 1\n",
    "                \n",
    "            # replace all repeated values with NaN, except the first\n",
    "            if delete:\n",
    "                end = i + 24\n",
    "                while (end < len(df[col])) and (not math.isnan(df.loc[ts_index[end], col])) and \\\n",
    "                      (val == df.loc[ts_index[end], col]):\n",
    "                    end += 1\n",
    "                for index in range(i+1, end):\n",
    "                    df.loc[ts_index[index], col] = math.nan\n",
    "                if not printed:\n",
    "                    print(station)\n",
    "                    print()\n",
    "                    printed = True\n",
    "                if not col_printed:\n",
    "                    print(col + ':')\n",
    "                    col_printed = True\n",
    "                print(str(ts_index[i]) + ' | ' + str(ts_index[end-1]) + '\\tValue: ' + str(val))\n",
    "                print()\n",
    "                i = end\n",
    "                \n",
    "            else:\n",
    "                i += 1\n",
    "                \n",
    "        # check remaining values to see if they exceed the reported range\n",
    "        while i < len(df[col]):\n",
    "            val = df.loc[ts_index[i], col]\n",
    "            if val > 999.99:\n",
    "                df.loc[ts_index[i], col] = math.nan\n",
    "                if not printed:\n",
    "                    print(station)\n",
    "                    print()\n",
    "                    printed = True\n",
    "                if not col_printed:\n",
    "                    print(col + ':')\n",
    "                    col_printed = True   \n",
    "                print(str(ts_index[i]) + '\\t\\t\\t\\tExcess Value: ' + str(val))\n",
    "                print()\n",
    "            i += 1\n",
    "            \n",
    "    if printed:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f0ae6ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnandVihar\n",
      "\n",
      "PM2.5:\n",
      "2019-03-19 09:00:00 | 2019-03-20 10:00:00\tValue: 182.0\n",
      "\n",
      "PM10:\n",
      "2016-09-04 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-12-31 20:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-02-09 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-02-09 01:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2019-06-11 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "\n",
      "AyaNagar\n",
      "\n",
      "PM2.5:\n",
      "2018-03-13 16:00:00 | 2018-03-16 12:00:00\tValue: 8.0\n",
      "\n",
      "2018-03-22 19:00:00 | 2018-03-27 18:00:00\tValue: 8.0\n",
      "\n",
      "2018-10-28 02:00:00 | 2018-10-29 11:00:00\tValue: 10.0\n",
      "\n",
      "2018-11-02 05:00:00 | 2018-11-03 15:00:00\tValue: 195.24\n",
      "\n",
      "NO2:\n",
      "2019-07-22 14:00:00 | 2019-07-25 08:00:00\tValue: 63.83\n",
      "\n",
      "\n",
      "CRRI\n",
      "\n",
      "PM10:\n",
      "2018-12-04 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "NO2:\n",
      "2018-02-14 19:00:00 | 2018-02-16 14:00:00\tValue: 24.0\n",
      "\n",
      "2018-03-17 17:00:00 | 2018-03-20 23:00:00\tValue: 24.0\n",
      "\n",
      "2021-03-31 12:00:00 | 2021-04-05 14:00:00\tValue: 178.1\n",
      "\n",
      "2021-04-19 02:00:00 | 2021-05-31 23:00:00\tValue: 178.1\n",
      "\n",
      "Ozone:\n",
      "2018-02-14 19:00:00 | 2018-02-16 14:00:00\tValue: 10.0\n",
      "\n",
      "2018-03-17 17:00:00 | 2018-03-20 23:00:00\tValue: 10.0\n",
      "\n",
      "2018-05-25 18:00:00 | 2018-06-05 11:00:00\tValue: 10.56\n",
      "\n",
      "\n",
      "DTU\n",
      "\n",
      "PM2.5:\n",
      "2017-11-08 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-11-08 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-11-08 14:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-11-08 15:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-11-08 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-11-08 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-11-08 19:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-11-08 20:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-12-08 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-12-08 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-05-14 13:00:00 | 2018-05-15 17:00:00\tValue: 48.0\n",
      "\n",
      "2018-11-08 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2019-01-18 15:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "PM10:\n",
      "2020-11-10 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-10 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-14 22:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-14 23:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-15 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-15 01:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-15 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-04-16 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-06 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-08 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-23 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-23 06:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-23 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-23 08:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "\n",
      "IGI\n",
      "\n",
      "PM10:\n",
      "2017-12-14 07:00:00 | 2017-12-16 11:00:00\tValue: 30.0\n",
      "\n",
      "\n",
      "ITO\n",
      "\n",
      "PM2.5:\n",
      "2018-11-16 23:00:00 | 2018-11-18 18:00:00\tValue: 120.0\n",
      "\n",
      "2020-03-23 03:00:00 | 2020-03-25 12:00:00\tValue: 94.0\n",
      "\n",
      "PM10:\n",
      "2018-11-16 23:00:00 | 2018-11-19 09:00:00\tValue: 173.0\n",
      "\n",
      "2020-03-23 03:00:00 | 2020-03-25 13:00:00\tValue: 110.0\n",
      "\n",
      "2020-11-14 20:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "NO2:\n",
      "2015-10-24 21:00:00 | 2015-10-26 04:00:00\tValue: 6.0\n",
      "\n",
      "2015-10-26 06:00:00 | 2015-10-28 15:00:00\tValue: 6.0\n",
      "\n",
      "2018-11-16 23:00:00 | 2018-11-19 09:00:00\tValue: 66.6\n",
      "\n",
      "SO2:\n",
      "2018-11-16 23:00:00 | 2018-11-19 09:00:00\tValue: 2.61\n",
      "\n",
      "\n",
      "Jahangirpuri\n",
      "\n",
      "PM2.5:\n",
      "2019-10-28 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "\n",
      "Mundka\n",
      "\n",
      "PM2.5:\n",
      "2020-11-09 23:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-10 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "\n",
      "Narela\n",
      "\n",
      "PM10:\n",
      "2019-11-04 04:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "\n",
      "NehruNagar\n",
      "\n",
      "PM2.5:\n",
      "2019-01-16 21:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "PM10:\n",
      "2019-01-16 22:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "\n",
      "NorthCampus\n",
      "\n",
      "PM2.5:\n",
      "2017-12-23 20:00:00 | 2017-12-26 13:00:00\tValue: 137.79\n",
      "\n",
      "2017-12-27 15:00:00 | 2017-12-29 12:00:00\tValue: 297.22\n",
      "\n",
      "PM10:\n",
      "2017-12-23 20:00:00 | 2017-12-26 13:00:00\tValue: 186.08\n",
      "\n",
      "2017-12-27 15:00:00 | 2017-12-29 12:00:00\tValue: 262.54\n",
      "\n",
      "NO2:\n",
      "2018-05-02 22:00:00 | 2018-05-05 12:00:00\tValue: 22.72\n",
      "\n",
      "2018-05-05 15:00:00 | 2018-05-08 16:00:00\tValue: 22.72\n",
      "\n",
      "2018-05-08 22:00:00 | 2018-05-13 16:00:00\tValue: 36.57\n",
      "\n",
      "2018-05-13 18:00:00 | 2018-05-15 19:00:00\tValue: 36.57\n",
      "\n",
      "Ozone:\n",
      "2017-12-23 20:00:00 | 2017-12-26 13:00:00\tValue: 26.64\n",
      "\n",
      "2017-12-27 15:00:00 | 2017-12-29 12:00:00\tValue: 21.29\n",
      "\n",
      "2021-03-23 19:00:00 | 2021-04-08 11:00:00\tValue: 10.29\n",
      "\n",
      "\n",
      "NSITDwarka\n",
      "\n",
      "PM2.5:\n",
      "2016-07-08 12:00:00 | 2016-07-10 12:00:00\tValue: 104.9\n",
      "\n",
      "2017-02-18 11:00:00 | 2017-02-20 11:00:00\tValue: 85.3\n",
      "\n",
      "2019-06-03 15:00:00 | 2019-06-04 22:00:00\tValue: 124.02\n",
      "\n",
      "SO2:\n",
      "2018-07-02 09:00:00 | 2018-07-03 09:00:00\tValue: 2.3\n",
      "\n",
      "2018-07-08 10:00:00 | 2018-07-09 10:00:00\tValue: 2.1\n",
      "\n",
      "2019-06-08 17:00:00 | 2019-06-10 01:00:00\tValue: 2.0\n",
      "\n",
      "\n",
      "RKPuram\n",
      "\n",
      "PM10:\n",
      "2015-09-13 09:00:00 | 2015-09-14 16:00:00\tValue: 265.0\n",
      "\n",
      "2021-04-17 08:00:00 | 2021-04-19 03:00:00\tValue: 241.0\n",
      "\n",
      "\n",
      "Shadipur\n",
      "\n",
      "SO2:\n",
      "2021-05-06 01:00:00 | 2021-05-07 06:00:00\tValue: 1.2\n",
      "\n",
      "2021-05-10 07:00:00 | 2021-05-11 07:00:00\tValue: 1.2\n",
      "\n",
      "\n",
      "Sirifort\n",
      "\n",
      "PM2.5:\n",
      "2016-11-06 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-06 20:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-06 21:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-07 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-16 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-16 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 03:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 06:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 08:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 09:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 14:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-17 19:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-18 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-19 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-19 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-19 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-19 20:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-20 04:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-20 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-21 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-21 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-21 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-21 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-21 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-21 15:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-21 21:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-21 22:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 03:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 04:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 06:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 08:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 09:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2016-11-22 14:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-13 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-14 03:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-15 22:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-17 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-17 15:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-19 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-19 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-19 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-20 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-20 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-20 23:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-21 03:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-21 04:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-21 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-21 06:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-21 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-21 08:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-21 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-21 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-21 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-24 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-01-24 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-14 22:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-14 23:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-16 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-23 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-23 19:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-23 22:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 03:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 04:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 06:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 08:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 09:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 19:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 20:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-24 21:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 03:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 04:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 06:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 14:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 15:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 20:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 21:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 22:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-25 23:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 01:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 08:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 09:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 14:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 15:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 19:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 20:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 21:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 22:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-26 23:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-27 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-27 01:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-27 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-27 03:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-27 04:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-27 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-27 06:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-02-27 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-04-09 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-04-10 06:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-04-10 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-04-11 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-04-17 13:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-02 15:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-10-20 01:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-10-20 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-10-20 03:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-10-20 04:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-10-20 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-10-20 08:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-10-20 09:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-10-20 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2017-11-10 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-01-12 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-01-31 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-03-21 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-03-23 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-03-31 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-04-06 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-04-06 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-04-16 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-04-17 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-05-02 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-05-16 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-05-16 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-05-28 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-01 14:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-07-03 14:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-08-01 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-11-07 23:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-11-08 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-11-08 01:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-11-08 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-12-16 22:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-12-29 15:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-12-29 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "PM10:\n",
      "2018-04-16 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-04-17 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-04-17 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-04-20 20:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-04-21 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-05-01 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-05-02 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-05-16 16:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-05-16 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-01 14:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-13 17:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-13 18:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-14 03:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-14 04:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-14 09:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-14 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-15 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-15 01:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-15 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-15 03:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-15 04:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-15 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-15 06:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-15 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-06-29 20:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2019-01-04 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2019-01-04 11:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2019-01-04 12:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-14 23:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-15 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-15 01:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-15 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-02-18 08:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-03-01 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-03-05 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-03-08 10:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-03-09 09:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-23 05:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-23 06:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-23 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-23 08:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2021-05-23 09:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "\n",
      "SoniaVihar\n",
      "\n",
      "PM10:\n",
      "2019-11-03 07:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2019-11-03 08:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "\n",
      "VivekVihar\n",
      "\n",
      "PM10:\n",
      "2018-12-23 23:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2018-12-24 00:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "2020-11-15 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "Ozone:\n",
      "2019-10-04 14:00:00 | 2019-10-05 15:00:00\tValue: 9.8\n",
      "\n",
      "\n",
      "Wazirpur\n",
      "\n",
      "PM10:\n",
      "2018-12-24 02:00:00\t\t\t\tExcess Value: 1000.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for station in station_data:\n",
    "    removeBadVals(station_data[station], station)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b05fd3",
   "metadata": {},
   "source": [
    "# Resave data for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b09ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in station_data:\n",
    "    station_data[station].to_csv('new_station_data/data_' + station + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f919e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
